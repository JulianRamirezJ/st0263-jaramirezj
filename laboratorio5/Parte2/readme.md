# Evidencias de realización del laboratorio 5 - 2 
## Julian Andres Ramirez Jimenez

## HDFS 

### Conexion al nodo master a través de la consola

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/0db6519b-9880-4c63-b8f3-05458e39f093)4

### GUI de Hue

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/0bfdc96b-7f09-406c-8ad4-b1ca8d1ca52d)

### Clonamos el repo y creamos la carpeta en el hdfs

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/5fcc80ef-2178-4df2-a1de-3f75be0145bc)

### Copiamos los archivos locales a hdfs y los listamos

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/f5e605cf-01a2-424d-b9b2-9218490f0ce0)

*Ahora podemos ver en HUe los archivos

### Ahora veremos copia de archivos via GUI

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/160c75a8-17f7-4090-896b-d173cbb7bfe7)
![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/de54a03e-aa31-4d18-8333-da9f77b70dc6)}

Podemos ver el archivo que acabamos de cargar:

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/1a4947c7-aa11-43e1-9619-4565aa3db9e3)

## S3

### Copiamos los datasets al bucket S3

![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/e4caa9b6-95ac-43b0-8b3e-36f4f35f2117)

 Asi quedan almacenados en el bucket:
 
 ![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/9f470b9f-cf15-4f74-a767-5a8e2cacaf0d)
 
 ### Aquí tenemos la interfaz de Hue en caso de que quisieramos subir manualmente los datasets utilizamos las opciones new y upload
 
 ![image](https://github.com/JulianRamirezJ/st0263-jaramirezj/assets/57159295/95f70e6e-306a-4d8c-9b80-0841e44e62a3)


